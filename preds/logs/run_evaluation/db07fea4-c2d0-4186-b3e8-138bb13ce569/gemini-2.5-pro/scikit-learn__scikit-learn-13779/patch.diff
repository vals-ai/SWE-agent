diff --git a/sklearn/ensemble/tests/test_voting.py b/sklearn/ensemble/tests/test_voting.py
index 2a19bc9a6..d56393f5b 100644
--- a/sklearn/ensemble/tests/test_voting.py
+++ b/sklearn/ensemble/tests/test_voting.py
@@ -13,6 +13,7 @@ from sklearn.naive_bayes import GaussianNB
 from sklearn.ensemble import RandomForestClassifier
 from sklearn.ensemble import VotingClassifier, VotingRegressor
 from sklearn.model_selection import GridSearchCV
+from sklearn.datasets import load_iris
 from sklearn import datasets
 from sklearn.model_selection import cross_val_score, train_test_split
 from sklearn.datasets import make_multilabel_classification
@@ -507,3 +508,55 @@ def test_transform():
             eclf3.transform(X).swapaxes(0, 1).reshape((4, 6)),
             eclf2.transform(X)
     )
+
+
+def test_none_estimator_with_weights():
+    """Check that VotingClassifier works with None estimator and weights."""
+    X, y = load_iris(return_X_y=True)
+    clf1 = LogisticRegression(random_state=123)
+    clf2 = RandomForestClassifier(random_state=123)
+    # We use predict_proba which requires all estimators to have predict_proba
+    # or voting='hard'
+    clf3 = GaussianNB()
+
+    # Test with sample_weight
+    weights = np.ones(y.shape[0])
+    eclf = VotingClassifier(
+        estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],
+        voting='soft'
+    )
+    eclf.fit(X, y, sample_weight=weights)
+    eclf.set_params(lr=None)
+    # Should not raise an error
+    eclf.fit(X, y, sample_weight=weights)
+
+    # Test with weights parameter
+    eclf = VotingClassifier(
+        estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],
+        voting='soft',
+        weights=[1, 1, 1]
+    )
+    eclf.fit(X, y)
+    eclf.set_params(lr=None)
+    # Should not raise an error
+    eclf.fit(X, y)
+
+    # Test with both weights and sample_weight
+    eclf = VotingClassifier(
+        estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],
+        voting='soft',
+        weights=[1, 1, 1]
+    )
+    eclf.fit(X, y, sample_weight=weights)
+    eclf.set_params(lr=None)
+    # Should not raise an error
+    eclf.fit(X, y, sample_weight=weights)
+
+    # Test VotingRegressor as well
+    reg1 = DummyRegressor(strategy='mean')
+    reg2 = DummyRegressor(strategy='median')
+    ereg = VotingRegressor(estimators=[('mean', reg1), ('median', reg2)])
+    ereg.fit(X_r, y_r, sample_weight=np.ones(y_r.shape[0]))
+    ereg.set_params(mean=None)
+    # Should not raise an error
+    ereg.fit(X_r, y_r, sample_weight=np.ones(y_r.shape[0]))
\ No newline at end of file
diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py
index 7afa7180c..f6470b00e 100644
--- a/sklearn/ensemble/voting.py
+++ b/sklearn/ensemble/voting.py
@@ -78,9 +78,10 @@ class _BaseVoting(_BaseComposition, TransformerMixin):
 
         if sample_weight is not None:
             for name, step in self.estimators:
-                if not has_fit_parameter(step, 'sample_weight'):
-                    raise ValueError('Underlying estimator \'%s\' does not'
-                                     ' support sample weights.' % name)
+                if step is not None:
+                    if not has_fit_parameter(step, 'sample_weight'):
+                        raise ValueError('Underlying estimator \'%s\' does not'
+                                         ' support sample weights.' % name)
 
         names, clfs = zip(*self.estimators)
         self._validate_names(names)
