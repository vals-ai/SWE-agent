diff --git a/seaborn/_core/plot.py b/seaborn/_core/plot.py
index 4f0290a4..42e3c12f 100644
--- a/seaborn/_core/plot.py
+++ b/seaborn/_core/plot.py
@@ -25,6 +25,7 @@ from seaborn._marks.base import Mark
 from seaborn._stats.base import Stat
 from seaborn._core.data import PlotData
 from seaborn._core.moves import Move
+from .scales import Nominal
 from seaborn._core.scales import Scale
 from seaborn._core.subplots import Subplots
 from seaborn._core.groupby import GroupBy
@@ -1475,21 +1476,20 @@ class Plotter:
 
                 axes_df = self._filter_subplot_data(df, view)
 
-                with pd.option_context("mode.use_inf_as_null", True):
-                    if keep_na:
-                        # The simpler thing to do would be x.dropna().reindex(x.index).
-                        # But that doesn't work with the way that the subset iteration
-                        # is written below, which assumes data for grouping vars.
-                        # Matplotlib (usually?) masks nan data, so this should "work".
-                        # Downstream code can also drop these rows, at some speed cost.
-                        present = axes_df.notna().all(axis=1)
-                        nulled = {}
-                        for axis in "xy":
-                            if axis in axes_df:
-                                nulled[axis] = axes_df[axis].where(present)
-                        axes_df = axes_df.assign(**nulled)
-                    else:
-                        axes_df = axes_df.dropna()
+                if keep_na:
+                    # The simpler thing to do would be x.dropna().reindex(x.index).
+                    # But that doesn't work with the way that the subset iteration
+                    # is written below, which assumes data for grouping vars.
+                    # Matplotlib (usually?) masks nan data, so this should "work".
+                    # Downstream code can also drop these rows, at some speed cost.
+                    present = axes_df.notna().all(axis=1)
+                    nulled = {}
+                    for axis in "xy":
+                        if axis in axes_df:
+                            nulled[axis] = axes_df[axis].where(present)
+                    axes_df = axes_df.assign(**nulled)
+                else:
+                    axes_df = axes_df.dropna()
 
                 subplot_keys = {}
                 for dim in ["col", "row"]:
@@ -1642,8 +1642,19 @@ class Plotter:
                         lo = cast(float, lo) - 0.5
                     if isinstance(b, str):
                         hi = cast(float, hi) + 0.5
+
+                    # Final adjustments for Nominal scales (within p._limits check)
+                    if axis_key in self._scales:
+                        scale = self._scales[axis_key]
+                        if isinstance(scale, Nominal) and getattr(scale, "_tight_limits", False):
+                            ax.margins(**{axis: 0})
+                        if axis == "y" and isinstance(scale, Nominal):
+                            ax.invert_yaxis()
+
+                    # Apply limits (still within p._limits check)
                     ax.set(**{f"{axis}lim": (lo, hi)})
 
+
         engine_default = None if p._target is not None else "tight"
         layout_engine = p._layout_spec.get("engine", engine_default)
         set_layout_engine(self._figure, layout_engine)
diff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py
index bbd71ec1..191ca60c 100644
--- a/seaborn/_core/scales.py
+++ b/seaborn/_core/scales.py
@@ -177,7 +177,10 @@ class Nominal(Scale):
             name = None  # To work around mpl<3.4 compat issues
 
             def set_default_locators_and_formatters(self, axis):
-                ...
+                # Disable grid for nominal axes (if it's a real axis)
+                if hasattr(axis, "grid"):
+                    axis.grid(False)
+                # TODO: Set locators/formatters if needed, currently uses default
                 # axis.set_major_locator(major_locator)
                 # if minor_locator is not None:
                 #     axis.set_minor_locator(minor_locator)
@@ -190,8 +193,9 @@ class Nominal(Scale):
             # TODO Currently just used in non-Coordinate contexts, but should
             # we use this to (A) set the padding we want for categorial plots
             # and (B) allow the values parameter for a Coordinate to set xlim/ylim
-            axis.set_view_interval(0, len(units_seed) - 1)
+            axis.set_view_interval(-0.5, len(units_seed) - 0.5)
 
+        new._tight_limits = True
         new._matplotlib_scale = mpl_scale
 
         # TODO array cast necessary to handle float/int mixture, which we need
diff --git a/seaborn/_oldcore.py b/seaborn/_oldcore.py
index 192af381..8944cd1a 100644
--- a/seaborn/_oldcore.py
+++ b/seaborn/_oldcore.py
@@ -1116,13 +1116,12 @@ class VectorPlotter:
                 parts = []
                 grouped = self.plot_data[var].groupby(self.converters[var], sort=False)
                 for converter, orig in grouped:
-                    with pd.option_context('mode.use_inf_as_null', True):
-                        orig = orig.dropna()
-                        if var in self.var_levels:
-                            # TODO this should happen in some centralized location
-                            # it is similar to GH2419, but more complicated because
-                            # supporting `order` in categorical plots is tricky
-                            orig = orig[orig.isin(self.var_levels[var])]
+                    orig = orig.dropna()
+                    if var in self.var_levels:
+                        # TODO this should happen in some centralized location
+                        # it is similar to GH2419, but more complicated because
+                        # supporting `order` in categorical plots is tricky
+                        orig = orig[orig.isin(self.var_levels[var])]
                     comp = pd.to_numeric(converter.convert_units(orig))
                     if converter.get_scale() == "log":
                         comp = np.log10(comp)
