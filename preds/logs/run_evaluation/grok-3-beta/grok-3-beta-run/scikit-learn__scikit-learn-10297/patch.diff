diff --git a/reproduce_ridge_classifier.py b/reproduce_ridge_classifier.py
new file mode 100644
index 000000000..bec63ac8f
--- /dev/null
+++ b/reproduce_ridge_classifier.py
@@ -0,0 +1,11 @@
+
+import numpy as np
+from sklearn import linear_model as lm
+
+#test database
+n = 100
+x = np.random.randn(n, 30)
+y = (np.random.normal(size = n) > 0).astype(int)  # Convert to binary labels (0 or 1)
+
+rr = lm.RidgeClassifierCV(alphas = np.arange(0.1, 1000, 0.1), normalize = True, 
+                                         store_cv_values = True).fit(x, y)
\ No newline at end of file
diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py
index 911c74ae3..51e4eb8e0 100644
--- a/sklearn/linear_model/ridge.py
+++ b/sklearn/linear_model/ridge.py
@@ -1301,6 +1301,11 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):
         weights inversely proportional to class frequencies in the input data
         as ``n_samples / (n_classes * np.bincount(y))``
 
+    store_cv_values : boolean, default False
+        Flag indicating if the cross-validation values corresponding to each alpha
+        should be stored in the ``cv_values_`` attribute (see below). This flag is
+        only compatible with ``cv=None`` (i.e. using Generalized Cross-Validation).
+
     Attributes
     ----------
     cv_values_ : array, shape = [n_samples, n_alphas] or \
@@ -1333,10 +1338,10 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):
     advantage of the multi-variate response support in Ridge.
     """
     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,
-                 normalize=False, scoring=None, cv=None, class_weight=None):
+                 normalize=False, scoring=None, cv=None, class_weight=None, store_cv_values=False):
         super(RidgeClassifierCV, self).__init__(
             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,
-            scoring=scoring, cv=cv)
+            scoring=scoring, cv=cv, store_cv_values=store_cv_values)
         self.class_weight = class_weight
 
     def fit(self, X, y, sample_weight=None):
diff --git a/test_ridge_classifier_cv_values.py b/test_ridge_classifier_cv_values.py
new file mode 100644
index 000000000..fc6c2d9a4
--- /dev/null
+++ b/test_ridge_classifier_cv_values.py
@@ -0,0 +1,18 @@
+
+import numpy as np
+from sklearn import linear_model as lm
+
+# Test database
+n = 100
+x = np.random.randn(n, 30)
+y = (np.random.normal(size = n) > 0).astype(int)  # Binary labels (0 or 1)
+
+# Test RidgeClassifierCV with store_cv_values=True
+rr = lm.RidgeClassifierCV(alphas=np.arange(0.1, 1.0, 0.1), normalize=True, store_cv_values=True).fit(x, y)
+
+# Check if cv_values_ attribute exists and is not None
+if hasattr(rr, 'cv_values_') and rr.cv_values_ is not None:
+    print('Success: cv_values_ attribute is populated.')
+    print('Shape of cv_values_:', rr.cv_values_.shape)
+else:
+    print('Failure: cv_values_ attribute is not populated.')
\ No newline at end of file
