diff --git a/additional_tests.py b/additional_tests.py
new file mode 100644
index 00000000..9d36798b
--- /dev/null
+++ b/additional_tests.py
@@ -0,0 +1,87 @@
+
+import xarray as xr
+import numpy as np
+
+# Test 1: Non-monotonic identical coordinates (should work after fix)
+yCoord1 = ['a', 'c', 'b']
+ds1 = xr.Dataset(
+    data_vars=dict(
+        data=(['x', 'y'], np.random.rand(3, 3))
+    ),
+    coords=dict(
+        x=[1, 2, 3],
+        y=yCoord1
+    )
+)
+ds2 = xr.Dataset(
+    data_vars=dict(
+        data=(['x', 'y'], np.random.rand(4, 3))
+    ),
+    coords=dict(
+        x=[4, 5, 6, 7],
+        y=yCoord1
+    )
+)
+try:
+    ds_combined1 = xr.combine_by_coords((ds1, ds2))
+    print("Test 1 passed: Non-monotonic identical coordinates combined successfully.")
+except Exception as e:
+    print(f"Test 1 failed: {str(e)}")
+
+# Test 2: Monotonic identical coordinates (should work)
+yCoord2 = ['a', 'b', 'c']
+ds3 = xr.Dataset(
+    data_vars=dict(
+        data=(['x', 'y'], np.random.rand(3, 3))
+    ),
+    coords=dict(
+        x=[1, 2, 3],
+        y=yCoord2
+    )
+)
+ds4 = xr.Dataset(
+    data_vars=dict(
+        data=(['x', 'y'], np.random.rand(4, 3))
+    ),
+    coords=dict(
+        x=[4, 5, 6, 7],
+        y=yCoord2
+    )
+)
+try:
+    ds_combined2 = xr.combine_by_coords((ds3, ds4))
+    print("Test 2 passed: Monotonic identical coordinates combined successfully.")
+except Exception as e:
+    print(f"Test 2 failed: {str(e)}")
+
+# Test 3: Non-monotonic non-identical coordinates (should fail with ValueError)
+yCoord3a = ['a', 'c', 'b']
+yCoord3b = ['a', 'b', 'd']
+ds5 = xr.Dataset(
+    data_vars=dict(
+        data=(['x', 'y'], np.random.rand(3, 3))
+    ),
+    coords=dict(
+        x=[1, 2, 3],
+        y=yCoord3a
+    )
+)
+ds6 = xr.Dataset(
+    data_vars=dict(
+        data=(['x', 'y'], np.random.rand(4, 3))
+    ),
+    coords=dict(
+        x=[4, 5, 6, 7],
+        y=yCoord3b
+    )
+)
+try:
+    ds_combined3 = xr.combine_by_coords((ds5, ds6))
+    print("Test 3 failed: Non-monotonic non-identical coordinates should not combine.")
+except ValueError as e:
+    if 'monotonic' in str(e).lower():
+        print("Test 3 passed: Correctly raised ValueError for non-monotonic non-identical coordinates.")
+    else:
+        print(f"Test 3 failed with unexpected error: {str(e)}")
+
+print("All tests completed.")
\ No newline at end of file
diff --git a/reproduce.py b/reproduce.py
new file mode 100644
index 00000000..05003f06
--- /dev/null
+++ b/reproduce.py
@@ -0,0 +1,30 @@
+
+import xarray as xr
+import numpy as np
+
+#yCoord = ['a', 'b', 'c']  # works without error
+yCoord = ['a', 'c', 'b']  # raises ValueError on combine
+
+ds1 = xr.Dataset(
+    data_vars=dict(
+        data=(['x', 'y'], np.random.rand(3, 3))
+    ),
+    coords=dict(
+        x=[1, 2, 3],
+        y=yCoord
+    )
+)
+
+ds2 = xr.Dataset(
+    data_vars=dict(
+        data=(['x', 'y'], np.random.rand(4, 3))
+    ),
+    coords = dict(
+        x=[4, 5, 6, 7],
+        y=yCoord
+    )
+)
+
+ds3 = xr.combine_by_coords((ds1, ds2))
+
+print("Script completed successfully, no errors.")
\ No newline at end of file
diff --git a/xarray/core/combine.py b/xarray/core/combine.py
index 37ae903b..25084235 100644
--- a/xarray/core/combine.py
+++ b/xarray/core/combine.py
@@ -503,12 +503,20 @@ def combine_by_coords(datasets, compat='no_conflicts', data_vars='all',
         # Check the overall coordinates are monotonically increasing
         for dim in concatenated.dims:
             if dim in concatenated:
-                indexes = concatenated.indexes.get(dim)
-                if not (indexes.is_monotonic_increasing
-                        or indexes.is_monotonic_decreasing):
-                    raise ValueError("Resulting object does not have monotonic"
-                                     " global indexes along dimension {}"
-                                     .format(dim))
+                # Skip monotonicity check for dimensions with identical coordinates across datasets
+                is_identical = True
+                first_coord = None
+                for ds in datasets_with_same_vars:
+                    if dim in ds.coords:
+                        if first_coord is None:
+                            first_coord = ds.coords[dim]
+                        elif not first_coord.identical(ds.coords[dim]):
+                            is_identical = False
+                            break
+                if not is_identical:
+                    indexes = concatenated.indexes.get(dim)
+                    if not (indexes.is_monotonic_increasing or indexes.is_monotonic_decreasing):
+                        raise ValueError("Resulting object does not have monotonic global indexes along dimension {}".format(dim))
         concatenated_grouped_by_data_vars.append(concatenated)
 
     return merge(concatenated_grouped_by_data_vars, compat=compat,
