diff --git a/examples/ensemble/plot_isolation_forest.py b/examples/ensemble/plot_isolation_forest.py
index 1b79072df..4c571c24f 100644
--- a/examples/ensemble/plot_isolation_forest.py
+++ b/examples/ensemble/plot_isolation_forest.py
@@ -4,7 +4,7 @@ IsolationForest example
 ==========================================
 
 An example using :class:`sklearn.ensemble.IsolationForest` for anomaly
-detection.
+detection. This example also highlights the `warm_start` parameter, which when set to `True`, allows reusing the solution of the previous call to fit and adding more estimators to the ensemble.
 
 The IsolationForest 'isolates' observations by randomly selecting a feature
 and then randomly selecting a split value between the maximum and minimum
diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py
index 8a1bd3625..2d7ccc1ba 100644
--- a/sklearn/ensemble/iforest.py
+++ b/sklearn/ensemble/iforest.py
@@ -91,6 +91,11 @@ class IsolationForest(BaseBagging, OutlierMixin):
         ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
         for more details.
 
+    warm_start : bool, optional (default=False)
+        When set to ``True``, reuse the solution of the previous call to fit
+        and add more estimators to the ensemble, otherwise, just fit a whole
+        new forest. See :term:`the Glossary <warm_start>`.
+
     behaviour : str, default='old'
         Behaviour of the ``decision_function`` which can be either 'old' or
         'new'. Passing ``behaviour='new'`` makes the ``decision_function``
@@ -171,6 +176,7 @@ class IsolationForest(BaseBagging, OutlierMixin):
                  max_features=1.,
                  bootstrap=False,
                  n_jobs=None,
+                 warm_start=False,
                  behaviour='old',
                  random_state=None,
                  verbose=0):
@@ -186,6 +192,7 @@ class IsolationForest(BaseBagging, OutlierMixin):
             max_samples=max_samples,
             max_features=max_features,
             n_jobs=n_jobs,
+            warm_start=warm_start,
             random_state=random_state,
             verbose=verbose)
 
diff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py
index 67ba2d7f9..a1727f8e8 100644
--- a/sklearn/ensemble/tests/test_iforest.py
+++ b/sklearn/ensemble/tests/test_iforest.py
@@ -359,3 +359,28 @@ def test_iforest_chunks_works2(
 ):
     test_iforest_works(contamination)
     assert mocked_get_chunk.call_count == n_predict_calls
+
+
+@pytest.mark.filterwarnings('ignore:default contamination')
+@pytest.mark.filterwarnings('ignore:behaviour="old"')
+def test_iforest_warm_start():
+    """Test IsolationForest warm_start option."""
+    rng = check_random_state(0)
+    X = rng.randn(100, 2)
+
+    # Fit with warm_start=False
+    clf1 = IsolationForest(n_estimators=10, warm_start=False, random_state=rng)
+    clf1.fit(X)
+    score1 = clf1.decision_function(X)
+
+    # Fit with warm_start=True, add more estimators
+    clf2 = IsolationForest(n_estimators=10, warm_start=True, random_state=rng)
+    clf2.fit(X)
+    clf2.set_params(n_estimators=20)
+    clf2.fit(X)
+    score2 = clf2.decision_function(X)
+
+    # Check that scores are different due to additional trees
+    assert len(clf2.estimators_) == 20
+    assert len(clf1.estimators_) == 10
+    assert not np.array_equal(score1, score2)
\ No newline at end of file
